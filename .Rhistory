cor(data$ontargetScoringAtt, data$accuratePass, method = "pearson")
cor(data$ontargetScoringAtt, data$accuratePass, method = "spearman")
cor(data$ontargetScoringAtt, data$accuratePass, method = "kendall")
simil(list(data$ontargetScoringAtt,data$accuratePass), method = "cosine")
simil(list(data$ontargetScoringAtt,data$accuratePass), method = "Jaccard")
simil(list(data$ontargetScoringAtt,data$accuratePass), method = "simple matching")
simil(list(data$ontargetScoringAtt,data$accuratePass), method = "Kulczynski1")
dist(list(data$ontargetScoringAtt,data$accuratePass), method = "Euclidean")
dist(list(data$ontargetScoringAtt,data$accuratePass), method = "Manhattan")
dist(list(data$ontargetScoringAtt,data$accuratePass), method = "supremum")
dist(list(data$ontargetScoringAtt,data$accuratePass), method = "Mahalanois")
dist(list(data$ontargetScoringAtt,data$accuratePass), method = "Mahalanobis")
? bruteforce
library(stuart)
? bruteforce
results <- bruteforce(data, list(ra = names(data)), 3,
cores = 1)  # numero de nucleos en la maquina
install.packages("lavaan")
results <- bruteforce(data, list(ra = names(data)), 3,
cores = 1)  # numero de nucleos en la maquina
summary(results)
results <- bruteforce(data, list(ra = names(data)),
cores = 1)  # numero de nucleos en la maquina
25.5/35
set.seed(42)
set.seed(42)
# creamos un subconjunto para que sea mas liviano
data <-
data_num %>%
select(equipo, accuratePass, wonTackle, goalsConceded,
ontargetScoringAtt, totalScoringAtt, saves) %>%
sample_n(700)
library(FSinR)
searcher <- searchAlgorithm('hillClimbing')
evaluator <- filterEvaluator('determinationCoefficient')
# Utilizamos una combinacion de estos para encontrar la combinacion de atributos que maximiza la funcion de evaluacion
results <- featureSelection(data, 'equipo', searcher, evaluator)
results$bestFeatures
directSearcher <- directSearchAlgorithm('selectKBest', list(k=3))
results <- directFeatureSelection(data_num_sub, 'equipo', directSearcher, evaluator)
results <- directFeatureSelection(data, 'equipo', directSearcher, evaluator)
results$bestFeatures
data2 <- data %>%
dplyr::select(-equipo) %>%
unique()
## Principal Component Analysis
PCA <- prcomp(data2)
barplot(PCA$sdev) ## graficamos el aporte de varianza de cada componente principal
barplot(PCA$sdev) ## graficamos el aporte de varianza de cada componente principal
features_PCA <-
predict(PCA) %>%
as.data.frame()
View(features_PCA)
? prcomp
View(features_PCA)
# Multidimensional scaling
d <- dist(data2) # distancias euclidianas entre entidades
data.MDS <- cmdscale(d, eig=TRUE, k = 2) # k es el numero de dimensiones de salida
features_MDS <-
data.MDS$points %>%
as.data.frame()
View(features_MDS)
View(features_PCA)
# nonparametric Multi Dinemsional Scaling
library(MASS)
data.nMDS <- isoMDS(d, k=2)
features_nMDS <-
data.nMDS$points %>%
as.data.frame()
View(features_nMDS)
# t-distributed Stochastic Neighbor Embedding
library(Rtsne)
data.tsne <- Rtsne(data2, dims = 3, perplexity=30, max_iter = 500)
features_tsne <-
data.tsne$Y %>%
as.data.frame()
# uniform manifold and projection
library(umap)
data.umap <- umap(data2)
features_umap <- data.umap$layout %>% as.data.frame()
ggplot(features_PCA, aes(PC1,PC2)) + geom_point()
ggplot(features_PCA, aes(PC1,PC2)) + geom_point()
View(features_PCA)
ggplot(features_PCA, aes(PC1,PC2)) + geom_point()
ggplot(features_PCA, aes(PC1,PC2))
pacman::p_load(tidyverse, proxy)
ggplot(features_PCA, aes(PC1,PC2))
ggplot(features_PCA, aes(PC1,PC2)) + geom_point()
ggplot(features_PCA, aes(PC1,PC2)) + geom_point()
ggplot(features_MDS, aes(V1,V2)) + geom_point()
ggplot(features_nMDS, aes(V1,V2)) + geom_point()
ggplot(features_tsne, aes(V1,V2)) + geom_point()
ggplot(features_umap, aes(V1,V2)) + geom_point()
library(datasauRus)
stats <- datasaurus_dozen %>%
group_by(dataset) %>%
summarize(
mean_x    = mean(x),
mean_y    = mean(y),
std_dev_x = sd(x),
std_dev_y = sd(y),
corr_pears  = cor(x, y, method = "pearson"),
corr_spear  = cor(x, y, method = "spearman"),
corr_kendall  = cor(x, y, method = "kendall"),
simil_cos = simil(list(x,y), method = "cosine") %>% as.numeric(),   # funcion simil en la libreria proxy
simil_jac = simil(list(x,y), method = "Jaccard") %>% as.numeric(),   # funcion simil en la libreria proxy
simil_sm = simil(list(x,y), method = "simple matching") %>% as.numeric(),   # funcion simil en la libreria proxy
simil_kul = simil(list(x,y), method = "Kulczynski1") %>% as.numeric(),   # funcion simil en la libreria proxy
dist_euc = dist(list(x,y), method = "Euclidean") %>% as.numeric(),
dist_manh = dist(list(x,y), method = "Manhattan") %>% as.numeric(),
dist_sup = dist(list(x,y), method = "supremum") %>% as.numeric(),
median_x    = median(x),
median_y    = median(y),
CV_x = sd(x) / mean(x),
CV_y = sd(y) / mean(y),
max_x = max(x),
max_y = max(y)
)
stats
# visualizamos las diferencias
ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset)) +
geom_point() +
theme_void() +
theme(legend.position = "none") +
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x,colour=dataset))+
geom_histogram(binwidth = 2)+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x,colour=dataset))+
geom_density()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, colour=dataset))+
geom_boxplot()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset))+
geom_violin()+
theme_void()+
theme(legend.position = "none")+
facet_wrap(~dataset, ncol=3)
ggplot(datasaurus_dozen, aes(x=x, y=dataset, colour=dataset)) +
geom_point() +
geom_boxplot() +
theme_void() +
theme(legend.position = "none")
pacman::p_load(magickm tidyverse)
set.seed(42)
pacman::p_load(magick, tidyverse)
# cargo imagen
imagen <- image_read("data/uai.jpg")
# genero variable con los datos de valores rgb
imagen_num <- as.numeric(image_data(imagen, channels = "rgb"))
# transformo a color para evaluar numero de colores
colorvector <- rgb(imagen_num[,,1], imagen_num[,,2], imagen_num[,,3], maxColorValue = 1)
colorvector  %>%  unique() %>%  length()
# creo dataframe con columnas rgb
colors_df <- col2rgb(colorvector) %>% t() %>% as_tibble()
View(colors_df)
? get_clust_tendency
? cluster::get_clust_tendency
# cargo librerias
pacman::p_load(tidyverse, Rtsne, mclust, e1071, cluster, flexclust, factoextra)
? cluster::get_clust_tendency
pacman::p_load(magick, tidyverse, factoextra)
? get_clust_tendency
# cargo imagen
imagen <- image_read("data/uai.jpg")
# genero variable con los datos de valores rgb
imagen_num <- as.numeric(image_data(imagen, channels = "rgb"))
# transformo a color para evaluar numero de colores
colorvector <- rgb(imagen_num[,,1], imagen_num[,,2], imagen_num[,,3], maxColorValue = 1)
colorvector  %>%  unique() %>%  length()
# creo dataframe con columnas rgb
colors_df <- col2rgb(colorvector) %>% t() %>% as_tibble()
# redondeo los colores para llegar a 30 colores
n <- 55
t_colors_df <- floor(colors_df/n)*n
# creo vector de colores transformado
t_colorvector <- rgb(t_colors_df/255)
# cargo imagen
imagen <- image_read("data/uai.jpg")
# genero variable con los datos de valores rgb
imagen_num <- as.numeric(image_data(imagen, channels = "rgb"))
# transformo a color para evaluar numero de colores
colorvector <- rgb(imagen_num[,,1], imagen_num[,,2], imagen_num[,,3], maxColorValue = 1)
colorvector  %>%  unique() %>%  length()
# creo dataframe con columnas rgb
colors_df <- col2rgb(colorvector) %>% t() %>% as_tibble()
get_clust_tendency(colors_df, n = 50, graph = FALSE)
get_clust_tendency(colors_df, n = 50, graph = TRUE)
get_clust_tendency(colors_df, n = 15, graph = TRUE)
gc()
get_clust_tendency(colors_df, n = 15, graph = TRUE)
get_clust_tendency(colors_df, n = 15, graph = FALSE)
get_clust_tendency(colors_df, n = 15, graph = FALSE)
pacman::p_load(magick, tidyverse, factoextra)
set.seed(42)
data_raw <- read_rds("data/partidos_futbol.rds")
data <- data_raw %>%
select(where(is.numeric()))
data <- data_raw %>%
select(where(is.numeric))
pacman::p_load(magick, tidyverse, factoextra, umap)
data.umap <- umap(data)
data <- data_raw %>%
select(where(is.numeric)) %>%
drop_na()
View(data_raw)
data <- data_raw %>%
select(where(is.numeric))
summary(data)
data <- data_raw %>%
select(where(is.numeric), -formationUsed) %>%
drop_na()
data.umap <- umap(data)
model.umap <- umap(data)
data.umap <- model.umap$layout
get_clust_tendency(data, n = 30)
get_clust_tendency(data.umap, n = 30, graph = FALSE)
PCA <-
data.PCA <- data %>%
prcomp() %>%
predict() %>%
as.data.frame()
get_clust_tendency(data.PCA, n = 30, graph = FALSE)
get_clust_tendency(data, n = 30, graph = FALSE)
? get_clust_tendency
ggplot(data.umap, aes(V1, V2)) + geom_point()
data.umap <-
model.umap %>% select(layout)
data.umap <-
model.umap$layout %>%
as_tibble()
data.umap <-
model.umap$layout %>%
as.data.frame()
View(data.umap)
ggplot(data.umap, aes(V1, V2)) + geom_point()
get_clust_tendency(data.umap, n = 30, graph = FALSE)
set.seed(42)
model.umap <- umap(data)
data.umap <-
model.umap$layout %>%
as.data.frame()
get_clust_tendency(data.umap, n = 30, graph = FALSE)
ggplot(data.umap, aes(V1, V2)) + geom_point()
ggplot(data.umap, aes(V1, V2)) +
geom_point()
tictoc::tic()
tictoc::toc()
kmedias(data.umap, k = 2)
# version basica de kmeans
kmedias <- function(data, k, itermax = 10){
# defino los centroides aleatoriamente seleccionando una muestra de la data recibida
centroids <- data[sample(1:nrow(data), k),]
# creo 2 variables auxiliares del mismo largo que me permitiran comparar si el algoritmo convergio
cluster <- 1:nrow(data)
cluster_iter <- cluster*0
# creo un for para iterar hasta las iteraciones maximas
for(i in 1:itermax){
if(!mean(cluster_iter == cluster)==1){ # si el algoritmo aun no converge
# calculo distancia de puntos con centroides de acuerdo a funcion
distk <- sqrt(matrix(rowSums(expand.grid(rowSums(centroids*centroids),rowSums(data*data))), # hago calculo de producto punto enntre matrices
nrow=nrow(centroids)) - # calculo el tamaño de la matriz resultante
2. * as.matrix(centroids) %*% t(as.matrix(data)))
cluster_iter <- cluster # reasigno la variable auxiliar al cluster obtenido en la iteracion anterior
cluster <- apply(distk, 2, function(x) which(x==min(x))[1]) # identifico el cluster mas cercano a cada punto
dist_min <- apply(distk, 2, function(x) min(x)) # identifico la distancia minima al cluster mas cercano
output <- data.frame(dist_min, data, cluster) # construyo salida del modelo juntando la data con sus clusters asignados
dist_clusts <- aggregate(.~cluster, output, mean) # agrego los datos por clusters obteniendo coordenadas y distancias medias
centroids <- dist_clusts[,-(1:2)] # redefino los centroides
print(i) # para ver en que iteracion va
}
}
return(list("clusters" = cluster, "centroides" = centroids)) # funcion devuelve una lista con los clusters de cada punto y con los centroides
}
kmedias(data.umap, k = 2)
tictoc::tic()
kmedias(data.umap, k = 2)
tictoc::toc()
tictoc::tic()
kmedias(data.umap, k = 2)
dur1 <- tictoc::toc()
tictoc::tic()
kmeans(data.umap, k = 2)
dur2 <- tictoc::toc()
kmeans(data.umap, 2)
tictoc::tic()
kmedias(data.umap, k = 2)
dur1 <- tictoc::toc()
tictoc::tic()
kmeans(data.umap, 2)
dur2 <- tictoc::toc()
kmedias(data.umap, 2)
tictoc::tic()
kmedias(data.umap, 2)
tictoc::toc()
tictoc::tic()
kmeans(data.umap, 2)
tictoc::toc()
tictoc::tic()
modelo1 <- kmedias(data.umap, 2)
tictoc::toc()
tictoc::tic()
modelo2 <- kmeans(data.umap, 2)
tictoc::toc()
p1 <- ggplot(data.umap, aes(V1, V2, col = modelo1$clusters))
p2 <- ggplot(data.umap, aes(V1, V2, col = modelo2$clusters))
p1 + p2
library(patchwork)
p1 + p2
p1 <- ggplot(data.umap, aes(V1, V2, col = modelo1$clusters)) +
geom_point()
p2 <- ggplot(data.umap, aes(V1, V2, col = modelo2$clusters)) +
geom_point()
p1 + p2
p2 <- ggplot(data.umap, aes(V1, V2, col = modelo2$cluster)) +
geom_point()
p1 + p2
p1 <- ggplot(data.umap, aes(V1, V2, col = modelo1$clusters)) +
geom_point() +
theme(legend.position = "bottom")
p2 <- ggplot(data.umap, aes(V1, V2, col = modelo2$cluster)) +
geom_point() +
theme(legend.position = "bottom")
p1 + p2
modelo1 <- kmedias(data.umap, 6)
tictoc::tic()
modelo1 <- kmedias(data.umap, 6)
modelo1 <- kmedias(data.umap, k = 6)
kmedias(data.umap, k = 6)
tictoc::tic()
modelo1 <- kmedias(data.umap, k = 6)
tictoc::toc()
# version basica de kmeans
kmedias <- function(data, k, itermax = 10){
# defino los centroides aleatoriamente seleccionando una muestra de la data recibida
centroids <- data[sample(1:nrow(data), k),]
# creo 2 variables auxiliares del mismo largo que me permitiran comparar si el algoritmo convergio
cluster <- 1:nrow(data)
cluster_iter <- cluster*0
# creo un for para iterar hasta las iteraciones maximas
for(i in 1:itermax){
if(!mean(cluster_iter == cluster)==1){ # si el algoritmo aun no converge
# calculo distancia de puntos con centroides de acuerdo a funcion
distk <- sqrt(matrix(rowSums(expand.grid(rowSums(centroids*centroids),rowSums(data*data))), # hago calculo de producto punto enntre matrices
nrow=nrow(centroids)) - # calculo el tamaño de la matriz resultante
2. * as.matrix(centroids) %*% t(as.matrix(data)))
cluster_iter <- cluster # reasigno la variable auxiliar al cluster obtenido en la iteracion anterior
cluster <- apply(distk, 2, function(x) which(x==min(x))[1]) # identifico el cluster mas cercano a cada punto
dist_min <- apply(distk, 2, function(x) min(x)) # identifico la distancia minima al cluster mas cercano
output <- data.frame(dist_min, data, cluster) # construyo salida del modelo juntando la data con sus clusters asignados
dist_clusts <- aggregate(.~cluster, output, mean) # agrego los datos por clusters obteniendo coordenadas y distancias medias
centroids <- dist_clusts[,-(1:2)] # redefino los centroides
#   print(i) # para ver en que iteracion va
}
}
return(list("clusters" = cluster, "centroides" = centroids)) # funcion devuelve una lista con los clusters de cada punto y con los centroides
}
# comparamos con algoritmo nativo kmeans ----
tictoc::tic()
modelo1 <- kmedias(data.umap, k = 6)
tictoc::toc()
tictoc::tic()
modelo2 <- kmeans(data.umap, 6)
tictoc::toc()
p1 <- ggplot(data.umap, aes(V1, V2, col = modelo1$clusters)) +
geom_point() +
theme(legend.position = "bottom")
p2 <- ggplot(data.umap, aes(V1, V2, col = modelo2$cluster)) +
geom_point() +
theme(legend.position = "bottom")
p1 + p2
p1 <- ggplot(data.umap, aes(V1, V2, col = factor(modelo1$clusters))) +
geom_point() +
theme(legend.position = "bottom")
p2 <- ggplot(data.umap, aes(V1, V2, col = factor(modelo2$cluster))) +
geom_point() +
theme(legend.position = "bottom")
p1 + p2
tictoc::tic()
modelo1 <- kmedias(data.umap, k = 12)
tictoc::toc()
tictoc::tic()
modelo2 <- kmeans(data.umap, 12)
tictoc::toc()
library(patchwork)
p1 <- ggplot(data.umap, aes(V1, V2, col = factor(modelo1$clusters))) +
geom_point() +
theme(legend.position = "bottom")
p2 <- ggplot(data.umap, aes(V1, V2, col = factor(modelo2$cluster))) +
geom_point() +
theme(legend.position = "bottom")
p1 + p2
p2 <- ggplot(data.umap, aes(V1, V2, col = factor(modelo2$cluster))) +
geom_point() +
theme(legend.position = "bottom",
legend.title = element_blank())
p1 + p2
p1 <- ggplot(data.umap, aes(V1, V2, col = factor(modelo1$clusters))) +
geom_point() +
theme(legend.position = "bottom",
legend.title = element_blank())
p2 <- ggplot(data.umap, aes(V1, V2, col = factor(modelo2$cluster))) +
geom_point() +
theme(legend.position = "bottom",
legend.title = element_blank())
p1 + p2
# ejemplo imagen UAI ----
imagen <- image_read("data/uai.jpg")
# genero variable con los datos de valores rgb
imagen_num <- imagen
# genero variable con los datos de valores rgb
imagen_num <- imagen %>%
image_data(channels = "rgb")
# genero variable con los datos de valores rgb
imagen_num <- imagen %>%
image_data(channels = "rgb") %>%
as.numeric()
# transformo a color para evaluar numero de colores
colorvector <- rgb(imagen_num[,,1],
imagen_num[,,2],
imagen_num[,,3],
maxColorValue = 1)
colorvector  %>%  unique() %>%  length()
# creo dataframe con columnas rgb
colors_df <-
col2rgb(colorvector) %>%
t() %>%
as_tibble()
View(colors_df)
# redondeo los colores para llegar a 30 colores
n <- 55
t_colors_df <- floor(colors_df/n)*n
# creo vector de colores transformado
t_colorvector <- rgb(t_colors_df/255)
t_colorvector  %>%  unique() %>%  length()
# creo una copia de la matriz original y la relleno con los valores tranformados
t_imagen_num <- imagen_num
t_imagen_num[,,1] <- t_colors_df$red/255
t_imagen_num[,,2] <- t_colors_df$green/255
t_imagen_num[,,3] <- t_colors_df$blue/255
graphics::rasterImage(imagen_num,  100, 300, 150, 350, interpolate = FALSE)
# dibujo la imagen original y la transformada
par(mfrow=c(2,1), cex=0.7, mai=c(0,0,0,0))
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(imagen_num,  100, 300, 150, 350, interpolate = FALSE)
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(t_imagen_num,  100, 300, 150, 350, interpolate = FALSE)
# extraigo los clusters de cada punto y creo una tabla para almacenarlos
t_colors_df_kmeans <-
tibble(cluster = modelo_kmeans$cluster) %>%
inner_join(centroides, by = "cluster")
# genero un modelo de kmeans con 30 centroides
modelo_kmeans <- kmeans(colors_df, 30, iter.max  = 20)
# extraigo los centroides y genero columna cluster
centroides <- modelo_kmeans$centers %>% as_tibble()
centroides$cluster <- 1:30
# extraigo los clusters de cada punto y creo una tabla para almacenarlos
t_colors_df_kmeans <-
tibble(cluster = modelo_kmeans$cluster) %>%
inner_join(centroides, by = "cluster")
# creo una copia de la imagen original y reemplazo valores por centroides obtenidos
t_imagen_num_kmeans <- imagen_num
t_imagen_num_kmeans[,,1] <- t_colors_df_kmeans$red/255
t_imagen_num_kmeans[,,2] <- t_colors_df_kmeans$green/255
t_imagen_num_kmeans[,,3] <- t_colors_df_kmeans$blue/255
# dibujo la imagen original, y las 2 transformadas
par(mfrow=c(3,1), cex=0.7, mai=c(0,0,0,0))
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(imagen_num,  100, 300, 150, 350, interpolate = FALSE)
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(t_imagen_num,  100, 300, 150, 350, interpolate = FALSE)
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(t_imagen_num_kmeans,  100, 300, 150, 350, interpolate = FALSE)
t_colors_df_kmeans_art <-
tibble(clusters = modelo_kmedias_artesanal$clusters) %>%
inner_join(centroides_artesa, by = "clusters")
# corro el modelo con las mismas condiciones del kmeans
modelo_kmedias_artesanal <- kmedias(colors_df, 30, itermax = 20)
centroides_artesa <- modelo_kmedias_artesanal$centroides %>% as_tibble()
centroides_artesa$clusters <- 1:30
t_colors_df_kmeans_art <-
tibble(clusters = modelo_kmedias_artesanal$clusters) %>%
inner_join(centroides_artesa, by = "clusters")
centroides_artesa <-
modelo_kmedias_artesanal$centroides %>%
as_tibble() %>%
mutate(clusters = 1:30)
# extraigo los centroides y genero columna cluster
centroides <-
modelo_kmeans$centers %>%
as_tibble() %>%
mutate(cluster = 1:30)
t_imagen_num_kmeans_art <- imagen_num
t_imagen_num_kmeans_art[,,1] <- t_colors_df_kmeans_art$red/255
t_imagen_num_kmeans_art[,,2] <- t_colors_df_kmeans_art$green/255
t_imagen_num_kmeans_art[,,3] <- t_colors_df_kmeans_art$blue/255
par(mfrow=c(4,1), cex=0.7, mai=c(0,0,0,0))
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(imagen_num,  100, 300, 150, 350, interpolate = FALSE)
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(t_imagen_num,  100, 300, 150, 350, interpolate = FALSE)
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(t_imagen_num_kmeans,  100, 300, 150, 350, interpolate = FALSE)
plot(c(100, 150), c(300, 350), type = "n", xlab = "", ylab = "", bty="n", axes=F)
graphics::rasterImage(t_imagen_num_kmeans_art,  100, 300, 150, 350, interpolate = FALSE)

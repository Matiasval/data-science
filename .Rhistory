# cargo librerias
pacman::p_load(tidyverse, Rtsne, ggdendro)
# cargo la data y aplico los mismos tratamientos que en el caso de DBScan
data_tsne  <- read.csv("data/video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(Critic_Score, User_Score, User_Count, Global_Sales) %>%
unique() %>%
Rtsne() %>%
.$Y %>%
as.data.frame()
data_tsne %>% summary()
#Distancia euclideana
d <- dist(data_tsne)
d %>% hist()
d %>% density() %>% lines()
d %>% hist()
d %>% density() %>% lines()
lines(density(d))
? hist
hist(d, freq = NULL)
lines(density(d))
hist(d)
ggplot(data_tsne) +
geom_point(aes(V1,V2))
set.seed(42)
# cargo la data y aplico los mismos tratamientos que en el caso de DBScan
data_tsne  <- read.csv("data/video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(Critic_Score, User_Score, User_Count, Global_Sales) %>%
unique() %>%
Rtsne() %>%
.$Y %>%
as.data.frame()
# exploramos la data
data_tsne %>% summary()
ggplot(data_tsne) +
geom_point(aes(V1,V2))
# analizo graficamente la distribucion de las distancias entre puntos
hist(d)
# hacemos un modelo jerarquico con distancia completa
model_complete <- hclust(d, method="complete")
# obtenemos una sintesis del modelo
summary(model_complete)
plot(model_complete)
# usamos la funcion dentro de R base para graficar el dendrograma
plot(model_complete)
# replicamos el grafico con ggplot
ggdendrogram(model_complete, rotate = TRUE, theme_dendro = TRUE)
# usamos la funcion dentro de R base para graficar el dendrograma
plot(model_complete)
abline(a = 40)
abline(h = 40)
abline(h = 40, col="red")
# replicamos el grafico con ggplot
ggdendrogram(model_complete, rotate = TRUE, theme_dendro = TRUE) +
geom_vline(xintercept = 40, col="red")
# replicamos el grafico con ggplot
ggdendrogram(model_complete, rotate = TRUE, theme_dendro = TRUE) +
geom_hline(yintercept = 40, col="red")
# replicamos el grafico con ggplot
ggdendrogram(model_complete, theme_dendro = TRUE) +
geom_vline(xintercept = 40, col="red")
# replicamos el grafico con ggplot
ggdendrogram(model_complete, theme_dendro = TRUE) +
geom_hline(yintercept = 40, col="red")
# analizamos el arbol si lo cortamos en h = 40
groups <- cutree(model_complete, h = 40)
groups %>% unique() %>% length()
data_tsne$cluster_complete <- groups
ggplot(data_tsne) +
geom_point(aes(V1,V2, col=cluster_complete))
data_tsne$cluster_complete <- factor(groups)
ggplot(data_tsne) +
geom_point(aes(V1,V2, col=cluster_complete))
ggplot(data_tsne) +
geom_point(aes(V1,V2, col=cluster_complete)) +
theme(legend.position = "none")
# evaluemos cuantos clusters obtenemos para los valores de h
res <- tibble("h" = quantile(d, probs  = (1:100)/100), n = 0)
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
ggplot(res, aes(h, n)) +
geom_point() +
scale_x_log10() +
scale_y_log10()
ggplot(res, aes(h, n)) +
geom_point()
ggplot(res, aes(h, n)) +
geom_point() +
scale_x_log10() +
scale_y_log10()
# creamos un vector vacio para almacenar los resultados
res <- tibble("h" = quantile(d, probs  = (1:100)/100), n = 0)
res
# recorremos los 100 percentiles y vamos rellenando el vector con el numero de grupos
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
data_tsne <- data_tsne %>% mutate(cluster_complete <- factor(groups))
data_tsne %>%
mutate(cluster_complete <- factor(groups)) %>%
group_by(cluster_complete) %>%
summarise(intra = sqrt(sd(V1)^2+sd(V2)^2))
data_tsne %>%
mutate(cluster_complete <- factor(groups)) %>%
group_by(cluster_complete) %>%
summarise(intra = sqrt(sd(V1)^2+sd(V2)^2)) %>%
mean()
data_tsne %>%
mutate(cluster_complete <- factor(groups)) %>%
group_by(cluster_complete) %>%
summarise(intra = sqrt(sd(V1)^2+sd(V2)^2)) %>%
summarise(mean(intra))
data_tsne %>%
mutate(cluster_complete <- factor(groups)) %>%
group_by(cluster_complete) %>%
summarise(intra = sqrt(sd(V1)^2+sd(V2)^2)) %>%
summarise(mean(intra)) %>%
as.numeric()
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <-   data_tsne %>%
mutate(cluster_complete <- factor(groups)) %>%
group_by(cluster_complete) %>%
summarise(intra = sqrt(sd(V1)^2+sd(V2)^2)) %>%
summarise(mean(intra)) %>%
as.numeric()
}
# visualizamos el numero de grupos vs h
ggplot(res, aes(h, n)) +
geom_point() +
scale_x_log10() +
scale_y_log10()
# visualizamos el numero de grupos vs h
ggplot(res, aes(h, n)) +
geom_point()
# creamos un vector vacio para almacenar los resultados
res <- tibble("h" = quantile(d, probs  = (1:100)/100), n = 0)
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <-   data_tsne %>%
mutate(cluster_complete <- factor(groups)) %>%
group_by(cluster_complete) %>%
summarise(intra = sqrt(sd(V1)^2+sd(V2)^2)) %>%
summarise(mean(intra)) %>%
as.numeric()
}
# visualizamos el numero de grupos vs h
ggplot(res, aes(h, n)) +
geom_point()
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <-   data_tsne %>%
mutate(cluster_complete <- factor(groups)) %>%
group_by(cluster_complete) %>%
summarise(intra = sd(V1)+sd(V2))) %>%
summarise(mean(intra)) %>%
as.numeric()
}
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <-   data_tsne %>%
mutate(cluster_complete <- factor(groups)) %>%
group_by(cluster_complete) %>%
summarise(intra = sd(V1)+sd(V2)) %>%
summarise(mean(intra)) %>%
as.numeric()
}
# visualizamos el numero de grupos vs h
ggplot(res, aes(h, n)) +
geom_point()
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
# visualizamos el numero de grupos vs h
ggplot(res, aes(h, n)) +
geom_point() +
scale_x_log10() +
scale_y_log10()
metodos_distancias <- c("euclidean", "maximum", "manhattan", "binary", "minkowski")
d2 <- dist(data_tsne, method = metodos_distancias[1])
metodos_agregacoin <- c("complete", "average", "median", "centroid," "single",
"ward.D", "ward.D", "mcquitty")
metodos_agregacoin <- c("complete", "average", "median", "centroid", "single",
"ward.D", "ward.D", "mcquitty")
model_ward = hclust(d, method=metodos_agregacion[1])
metodos_agregacion <- c("complete", "average", "median", "centroid", "single",
"ward.D", "ward.D", "mcquitty")
d2 <- dist(data_tsne, method = metodos_distancias[1])
model_ward = hclust(d, method=metodos_agregacion[1])
# visualizamos el numero de grupos vs h
ggplot(res, aes(h, n)) +
geom_point()
d2 <- dist(data_tsne, method = metodos_distancias[1])
model2 <- hclust(d2, method=metodos_agregacion[1])
summary(model2)
summary(model2)
k =12
res$dist_k <- abs(res$n - k)
res$dist_k == min(res$dist_k)
which(res$dist_k == min(res$dist_k))
res$h[which(res$dist_k == min(res$dist_k))]
res$h[which(res$dist_k == min(res$dist_k))][1]
h_k <- res$h[which(res$dist_k == min(res$dist_k))][1]
groups <- cutree(model_i, h = h_k)
clusters_jer <- function(data, i_d, i_a, k){
d_i <- dist(data, method = metodos_distancias[i_d])
model_i <- hclust(d2, method=metodos_agregacion[i_a])
# creamos un vector vacio para almacenar los resultados
res <- tibble("h" = quantile(d_i, probs  = (1:100)/100), n = 0)
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_i, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
res$dist_k <- abs(res$n - k)
h_k <- res$h[which(res$dist_k == min(res$dist_k))][1]
groups <- cutree(model_i, h = h_k)
data$cluster <- factor(groups)
ggplot(data) +
geom_point(aes(V1,V2, col=cluster)) +
theme(legend.position = "none")
}
clusters_jer(data_tsne, 1, 1, 12)
clusters_jer <- function(data, i_d, i_a, k){
d_i <- dist(data, method = metodos_distancias[i_d])
model_i <- hclust(d2, method=metodos_agregacion[i_a])
# creamos un vector vacio para almacenar los resultados
res <- tibble("h" = quantile(d_i, probs  = (1:100)/100), n = 0)
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_i, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
res$dist_k <- abs(res$n - k)
h_k <- res$h[which(res$dist_k == min(res$dist_k))][1]
groups <- cutree(model_i, h = h_k)
data$cluster <- factor(groups)
ggplot(data) +
geom_point(aes(V1,V2, col=cluster)) +
theme(legend.position = "none") +
ggtitle(paste0(k," clusters con distancia ",
metodos_distancias[i_d]," y metodo de agregacion ",
metodos_agregacion[i_a]))
}
clusters_jer(data_tsne, 1, 1, 12)
clusters_jer <- function(data, i_d, i_a, k){
d_i <- dist(data, method = metodos_distancias[i_d])
model_i <- hclust(d2, method=metodos_agregacion[i_a])
# creamos un vector vacio para almacenar los resultados
res <- tibble("h" = quantile(d_i, probs  = (1:100)/100), n = 0)
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_i, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
res$dist_k <- abs(res$n - k)
h_k <- res$h[which(res$dist_k == min(res$dist_k))][1]
groups <- cutree(model_i, h = h_k)
data$cluster <- factor(groups)
ggplot(data) +
geom_point(aes(V1,V2, col=cluster)) +
theme(legend.position = "none") +
ggtitle(paste0(k," clusters con distancia ",
metodos_distancias[i_d],
"\n y metodo de agregacion ",
metodos_agregacion[i_a]))
}
clusters_jer <- function(data, i_d, i_a, k){
d_i <- dist(data, method = metodos_distancias[i_d])
model_i <- hclust(d2, method=metodos_agregacion[i_a])
res <- tibble("h" = quantile(d_i, probs  = (1:100)/100), n = 0)
for (i in 1:100){
groups <- cutree(model_i, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
# encontramos la distnacia que cumple la restriccion de clusters
res$dist_k <- abs(res$n - k)
h_k <- res$h[which(res$dist_k == min(res$dist_k))][1]
groups <- cutree(model_i, h = h_k)
data$cluster <- factor(groups)
ggplot(data) +
geom_point(aes(V1,V2, col=cluster)) +
theme(legend.position = "none") +
ggtitle(paste0(k," clusters con distancia ",
metodos_distancias[i_d],
"\n y metodo de agregacion ",
metodos_agregacion[i_a]))
}
clusters_jer(data_tsne, 1, 1, 12)
clusters_jer(data_tsne, 4, 1, 12)
clusters_jer(data_tsne, 2, 1, 12)
clusters_jer(data_tsne, 3, 1, 12)
clusters_jer(data_tsne, 3, 5, 12)
# probamos la funcion con distintos valores de i_d, i_a, y k
clusters_jer(data_tsne, 1, 1, 3)
# cargo librerias
pacman::p_load(tidyverse, Rtsne, ggdendro)
set.seed(42)
# cargo la data y aplico los mismos tratamientos que en el caso de DBScan
data_tsne  <- read.csv("data/video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(Critic_Score, User_Score, User_Count, Global_Sales) %>%
unique() %>%
Rtsne() %>%
.$Y %>%
as.data.frame()
# exploramos la data
data_tsne %>% summary()
ggplot(data_tsne) +
geom_point(aes(V1,V2))
# calculamos la distancia euclideana
d <- dist(data_tsne)
# analizo graficamente la distribucion de las distancias entre puntos
hist(d)
# hacemos un modelo jerarquico con distancia completa
model_complete <- hclust(d, method="complete")
# obtenemos una sintesis del modelo
summary(model_complete)
# usamos la funcion dentro de R base para graficar el dendrograma
plot(model_complete)
abline(h = 40, col="red")
# replicamos el grafico con ggplot
ggdendrogram(model_complete, theme_dendro = TRUE) +
geom_hline(yintercept = 40, col="red")
# analizamos el arbol si lo cortamos en h = 40
groups <- cutree(model_complete, h = 40)
groups %>% unique() %>% length()
# asignamos grupos a los datos creando una nueva variable
data_tsne$cluster_complete <- factor(groups)
# visualizamos los grupos resultantes
ggplot(data_tsne) +
geom_point(aes(V1,V2, col=cluster_complete)) +
theme(legend.position = "none")
# creamos un vector vacio para almacenar los resultados
res <- tibble("h" = quantile(d, probs  = (1:100)/100), n = 0)
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
# visualizamos el numero de grupos vs h
ggplot(res, aes(h, n)) +
geom_point()
metodos_distancias <- c("euclidean", "maximum", "manhattan", "binary", "minkowski")
metodos_agregacion <- c("complete", "average", "median", "centroid", "single",
"ward.D", "ward.D", "mcquitty")
d2 <- dist(data_tsne, method = metodos_distancias[1])
model2 <- hclust(d2, method=metodos_agregacion[1])
summary(model2)
clusters_jer <- function(data, i_d, i_a, k){
d_i <- dist(data, method = metodos_distancias[i_d])
model_i <- hclust(d2, method=metodos_agregacion[i_a])
res <- tibble("h" = quantile(d_i, probs  = (1:100)/100), n = 0)
for (i in 1:100){
groups <- cutree(model_i, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
# encontramos la minima distancia que cumple el nro de clusters
res$dist_k <- abs(res$n - k)
h_k <- res$h[which(res$dist_k == min(res$dist_k))][1]
groups <- cutree(model_i, h = h_k)
data$cluster <- factor(groups)
ggplot(data) +
geom_point(aes(V1,V2, col=cluster)) +
theme(legend.position = "none") +
ggtitle(paste0(k," clusters con distancia ",
metodos_distancias[i_d],
"\n y metodo de agregacion ",
metodos_agregacion[i_a]))
}
# probamos la funcion con distintos valores de i_d, i_a, y k
clusters_jer(data_tsne, 1, 1, 3)
# probamos la funcion con distintos valores de i_d, i_a, y k
clusters_jer(data_tsne, 1, 1, 13)
# probamos la funcion con distintos valores de i_d, i_a, y k
clusters_jer(data_tsne, 1, 5, 13)
clusters_jer <- function(data, i_d, i_a, k){
d_i <- dist(data, method = metodos_distancias[i_d])
model_i <- hclust(d2, method=metodos_agregacion[i_a])
res <- tibble("h" = quantile(d_i, probs  = (1:100)/100), n = 0)
for (i in 1:100){
groups <- cutree(model_i, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
# encontramos la minima distancia que cumple el nro de clusters
res$dist_k <- abs(res$n - k)
h_k <- res$h[which(res$dist_k == min(res$dist_k))][1]
groups <- cutree(model_i, h = h_k)
data$cluster <- factor(groups)
ggplot(data) +
geom_point(aes(V1,V2, col=cluster)) +
theme(legend.position = "none") +
ggtitle(paste0(k," clusters con distancia ",
metodos_distancias[i_d],
"\n y método de agregación ",
metodos_agregacion[i_a]))
}
# probamos la funcion con distintos valores de i_d, i_a, y k
clusters_jer(data_tsne, 1, 5, 13)
? kmeans
? dbscan
? hclust
# cargo librerias
pacman::p_load(tidyverse, Rtsne, ggdendro)
set.seed(42)
# cargo la data y aplico los mismos tratamientos que en el caso de DBScan
data_tsne  <- read.csv("data/video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(Critic_Score, User_Score, User_Count, Global_Sales) %>%
unique() %>%
Rtsne() %>%
.$Y %>%
as.data.frame()
View(data_tsne)
# exploramos la data
data_tsne %>% summary()
ggplot(data_tsne) +
geom_point(aes(V1,V2))
# calculamos la distancia euclideana
d <- dist(data_tsne)
# analizo graficamente la distribucion de las distancias entre puntos
hist(d)
# obtenemos una sintesis del modelo
summary(model_complete)
# hacemos un modelo jerarquico con distancia completa
model_complete <- hclust(d, method="complete")
# obtenemos una sintesis del modelo
summary(model_complete)
? hclust
knitr::opts_chunk$set(echo = TRUE)
data <- cars
View(data)
modelo_clust <- hclust(dist(data), method = "complete")
plot(modelo_clust)
# usamos la funcion dentro de R base para graficar el dendrograma
plot(model_complete)
abline(h = 40, col="red")
# replicamos el grafico con ggplot
ggdendrogram(model_complete, theme_dendro = TRUE) +
geom_hline(yintercept = 40, col="red")
# analizamos el arbol si lo cortamos en h = 40
groups <- cutree(model_complete, h = 40)
groups %>% unique() %>% length()
# asignamos grupos a los datos creando una nueva variable
data_tsne$cluster_complete <- factor(groups)
View(data_tsne)
# visualizamos los grupos resultantes
ggplot(data_tsne) +
geom_point(aes(V1,V2, col=cluster_complete)) +
theme(legend.position = "none")
# creamos un vector vacio para almacenar los resultados
res <- tibble("h" = quantile(d, probs  = (1:100)/100), n = 0)
View(res)
# recorremos los 100 percentiles y vamos rellenando el vector con la distancia intra cluster
for (i in 1:100){
groups <- cutree(model_complete, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
# visualizamos el numero de grupos vs h
ggplot(res, aes(h, n)) +
geom_point()
? dist
d2 <- dist(data_tsne, method = metodos_distancias[1])
metodos_distancias <- c("euclidean", "maximum", "manhattan", "binary", "minkowski")
metodos_agregacion <- c("complete", "average", "median", "centroid", "single",
"ward.D", "ward.D", "mcquitty")
d2 <- dist(data_tsne, method = metodos_distancias[1])
model2 <- hclust(d2, method=metodos_agregacion[5])
summary(model2)
clusters_jer <- function(data, i_d, i_a, k){
d_i <- dist(data, method = metodos_distancias[i_d])
model_i <- hclust(d_i, method=metodos_agregacion[i_a])
res <- tibble("h" = quantile(d_i, probs  = (1:100)/100), n = 0)
for (i in 1:100){
groups <- cutree(model_i, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
# encontramos la minima distancia que cumple el nro de clusters
res$dist_k <- abs(res$n - k)
h_k <- res$h[which(res$dist_k == min(res$dist_k))][1]
groups <- cutree(model_i, h = h_k)
data$cluster <- factor(groups)
ggplot(data) +
geom_point(aes(V1,V2, col=cluster)) +
theme(legend.position = "none") +
ggtitle(paste0(k," clusters con distancia ",
metodos_distancias[i_d],
"\n y método de agregación ",
metodos_agregacion[i_a]))
}
# probamos la funcion con distintos valores de i_d, i_a, y k
clusters_jer(data_tsne, 1, 1, 13)
# probamos la funcion con distintos valores de i_d, i_a, y k
clusters_jer(data_tsne, 1, 5, 13)
# probamos la funcion con distintos valores de i_d, i_a, y k
clusters_jer(data_tsne, 2, 5, 13)
